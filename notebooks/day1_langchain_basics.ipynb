{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d54c16",
   "metadata": {},
   "source": [
    "# LangChain Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3990592",
   "metadata": {},
   "source": [
    "## 1) Load API Key from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622be630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ API Key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "print(\"GROQ API Key loaded successfully.\" if groq_api_key else \"Failed to load GROQ API Key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3fec8",
   "metadata": {},
   "source": [
    "## 2) LangChain-Powered LLM using Groq\n",
    "We get the access to LLaMA3 models via Groq API through LangChain, and we try a sample message and visualize the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ded192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source AI language model that is designed to be a more efficient and scalable alternative to other popular language models like BERT and RoBERTa. LangChain is built on top of the transformer architecture and uses a technique called \"language chain\" to process and generate text.\n",
      "\n",
      "The main innovation behind LangChain is its ability to process text in a more sequential manner, rather than processing the entire input text all at once. This allows LangChain to be more efficient and scalable, making it possible to process longer and more complex texts.\n",
      "\n",
      "LangChain is trained on a large corpus of text data and uses a combination of supervised and unsupervised learning techniques to learn the patterns and structures of language. It can be fine-tuned for specific tasks such as language translation, text summarization, and text generation.\n",
      "\n",
      "Some of the key features of LangChain include:\n",
      "\n",
      "* Efficient processing of long and complex texts\n",
      "* Ability to generate high-quality text that is similar to human-written text\n",
      "* Fine-tuning for specific tasks and domains\n",
      "* Open-source and community-driven development\n",
      "\n",
      "LangChain has been shown to be effective in a variety of NLP tasks, including language translation, text summarization, and text generation. It is also being explored for its potential applications in areas such as language education, content creation, and customer service chatbots.\n",
      "\n",
      "Overall, LangChain is an exciting development in the field of NLP, and its innovative approach to language processing has the potential to revolutionize the way we interact with language and machines.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Initialize the Groq LLM with the API key and model name\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama3-8b-8192\"\n",
    ")\n",
    "\n",
    "# Calling the Groq LLM with a sample message\n",
    "response = llm([HumanMessage(content=\"Hello, Can you explain what is LangChain?\")])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f69f34",
   "metadata": {},
   "source": [
    "## 3) Using PromptTemplate + LLM Chain\n",
    "We aim to create a PromptTemplate that takes one variable \"topic\" to a template to explain that topic, then link between the prompt and Groq LLM using LLMChain. Finally, we try to pass a topic and we get the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eab96c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What is LangChain?**\n",
      "\n",
      "LangChain is a type of artificial intelligence (AI) model that helps computers understand and generate human-like language. It's like a super-smart, language- fluent assistant that can communicate with humans in a way that feels natural and conversational.\n",
      "\n",
      "**How does it work?**\n",
      "\n",
      "Imagine you're having a conversation with a friend. You share your thoughts, and your friend responds with their own thoughts. LangChain works in a similar way. It's trained on a massive amount of text data (think books, articles, conversations) to learn the patterns and structures of human language.\n",
      "\n",
      "When you ask LangChain a question or give it a prompt, it uses its understanding of language to generate a response. This response can be a sentence, a paragraph, or even a longer piece of text.\n",
      "\n",
      "**What can LangChain do?**\n",
      "\n",
      "LangChain is incredibly versatile. Here are a few examples of what it can do:\n",
      "\n",
      "1. **Answer questions**: LangChain can provide answers to a wide range of questions, from simple facts to more complex topics.\n",
      "2. **Generate text**: LangChain can create text based on a prompt, such as a product description, a short story, or even a news article.\n",
      "3. **Translate languages**: LangChain can translate text from one language to another, helping to break down language barriers.\n",
      "4. **Summarize content**: LangChain can summarize long pieces of text, like articles or documents, into shorter, more digestible versions.\n",
      "\n",
      "**Why is LangChain important?**\n",
      "\n",
      "LangChain has many potential applications, such as:\n",
      "\n",
      "1. **Improving customer service**: LangChain can help chatbots and virtual assistants understand and respond to customer queries more effectively.\n",
      "2. **Enhancing language learning**: LangChain can assist language learners by providing personalized language lessons and exercises.\n",
      "3. **Accelerating content creation**: LangChain can help writers and content creators generate ideas and draft text more quickly.\n",
      "\n",
      "In summary, LangChain is a powerful AI model that can understand and generate human language, enabling it to assist with a wide range of tasks and applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Creating a PromptTemplate with one variable which is 'topic'\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template = \"Explain {topic} to a beginner in simple terms.\"\n",
    ")\n",
    "\n",
    "# Creating an LLMChain that links the prompt template with the LLM\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "response = chain.run(topic=\"LangChain\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba5fcc",
   "metadata": {},
   "source": [
    "## 4) Add Memory to LangChain Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2b2ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7656\\1681130061.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7656\\1681130061.py:6: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, I'm Tarneem\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI Assistant: Nice to meet you, Tarneem! I'm Ada, a large language model trained by Meta AI. I've been designed to assist and converse with humans in a helpful and informative way. Did you know that I've been trained on a massive dataset of text from the internet, which includes over 45 billion parameters? This allows me to understand and respond to a wide range of questions and topics. What brings you here today, Tarneem?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I'm Tarneem\n",
      "AI: Nice to meet you, Tarneem! I'm Ada, a large language model trained by Meta AI. I've been designed to assist and converse with humans in a helpful and informative way. Did you know that I've been trained on a massive dataset of text from the internet, which includes over 45 billion parameters? This allows me to understand and respond to a wide range of questions and topics. What brings you here today, Tarneem?\n",
      "Human: What did I just say?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI Assistant: You said \"Hi, I'm Tarneem\"!\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response1 = conversation.predict(input=\"Hi, I'm Tarneem\")\n",
    "print(\"AI Assistant:\", response1)\n",
    "\n",
    "response2 = conversation.predict(input=\"What did I just say?\")\n",
    "print(\"AI Assistant:\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd6f0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Content:\n",
      "\n",
      "Human: Hi, I'm Tarneem\n",
      "AI: Nice to meet you, Tarneem! I'm Ada, a large language model trained by Meta AI. I've been designed to assist and converse with humans in a helpful and informative way. Did you know that I've been trained on a massive dataset of text from the internet, which includes over 45 billion parameters? This allows me to understand and respond to a wide range of questions and topics. What brings you here today, Tarneem?\n",
      "Human: What did I just say?\n",
      "AI: You said \"Hi, I'm Tarneem\"!\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory Content:\\n\\n\" + memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e84605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
